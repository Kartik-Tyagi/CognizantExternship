{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1b7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformers with pretrained text generation models\n",
    "#Utilizing the provided transformer_template.ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d904fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76722882085c4843bf9ff884bd23f914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyagi\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tyagi\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a83f00345f4be89dbe541791620011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea5eedd46824f3d905ef7ab9ea7553c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f28cf05b88648e2a72bc8e1c3340457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f4ab8fd7f64938884856ba8327832e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff228405a3b4800ba54790a44908f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabfab76e05545188dace91afd7e28bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the future, education will shift from a classroom to a library. In the meantime, all students will be able to read and write.\n",
      "\n",
      "In a recent study, we investigated the impacts of this change on literacy by studying students from kindergarten through\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load GPT-2 text generation model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Set your prompt\n",
    "prompt = 'In the future, education will'\n",
    "\n",
    "# Generate text\n",
    "result = generator(prompt, max_length=50, temperature=0.7)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c64426c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The impact of AI on the future of work is clear.\n",
      "\n",
      "\"The AI market is a very complex one,\" says Celine. \"There are many different types of AI, but the main one is the human-driven AI. We're seeing a lot of AI in the workplace, but there is also a lot of automation in the workplace. The human-driven AI is a big part of the problem. The problem is that there are so many different types of AI that are being used to automate jobs.\"\n",
      "\n",
      "The problem is that there are so many different types of AI that are being used to\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The impact of AI on the future of work is clear.\n",
      "\n",
      "The UK's Labour government is considering a bill to allow the government to hire AI workers at the same time as it moves ahead with plans to hire more than 3,000 more.\n",
      "\n",
      "The government has said it is considering a bill that would allow employers to hire\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The impact of AI on the future of work has been dramatic in the last decade. A big part of this is the fact that technology is being replaced by machines.\n",
      "\n",
      "In the early 1980s I was working on the first 'computer science' project to address the need for an artificial intelligence system. The project was called the '\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a kingdom, the country of Israel, which was born of an immense fertility rate which was constantly growing, after the time of Christ, at a rate of 3 per cent per annum.\n",
      "\n",
      "The first generation of the Hebrews, as an adult, were the \"garter of Israel,\" and these were not mere princes. They were descended from the descendants of kings whom God had chosen for this purpose.\n",
      "\n",
      "When it was established that God had chosen the country for the common good, the children of Israel were to be educated by the children of Abraham and Isaac, with the help of their fathers, by the gift of the Holy Spirit. The sons of Israel were to learn by the Holy Spirit, \"when God will bless the children of Israel who are born of Abraham and Isaac, and bring them to the land of Canaan, and to the land of Judah, and to the land of the\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a kingdom called the Kingdom of the Gods. The King of Gods, the King of the Gods, the King of the Gods, the King of the Gods, the King of the Gods, the King of the Gods, the King of the Gods, the King of the Gods, the King of the Gods, the King of the Gods, the King of the Gods, the King of the Gods, the King of the Gods, the King of the Gods, the King of the Gods, the King of\n",
      "----------------------------------\n",
      "Once upon a time, there was a kingdom of the gods, and it was called the Kingdom of the Gods. The gods were called the gods of the earth, and they were called the gods of the sky. The gods were called the gods of the sea, and they were called the\n"
     ]
    }
   ],
   "source": [
    "# Experiment with different prompts\n",
    "\n",
    "import random\n",
    "\n",
    "num_return_sequences = 3\n",
    "\n",
    "for i in range(num_return_sequences):\n",
    "    print(\"----------------------------------\")\n",
    "    prompt = 'The impact of AI on the future of work'\n",
    "    result = generator(prompt, max_length=int(random.random()*200 + 50), temperature=int(random.random()*10 + 1)/10)\n",
    "    print(result[0]['generated_text'])\n",
    "for i in range(num_return_sequences):\n",
    "    print(\"----------------------------------\")\n",
    "    prompt = 'Once upon a time, there was a kingdom'\n",
    "    result = generator(prompt, max_length=int(random.random()*200 + 50), temperature=int(random.random()*10 + 1)/10)\n",
    "    print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9ee6614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dragons vs AI\n",
      "\n",
      "The AI is a very powerful tool that can be used to create a very powerful AI. It is very easy to use, and it is very easy to use.\n",
      "\n",
      "The AI is a very powerful tool that can be used to create a very powerful AI. It is very easy to use, and it is very easy to use. The AI is a very powerful tool that can be used to create a very powerful AI. It is very easy to use, and\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dragons vs AI\n",
      "\n",
      "The AI is a very powerful tool that can be used to create a lot of interesting and interesting scenarios. It can be used to create a lot of interesting and interesting scenarios. It can be used to create a lot of interesting and interesting scenarios.\n",
      "\n",
      "The AI is a very powerful tool that can be used to create a lot of interesting and interesting scenarios. It can be used to create a lot of interesting and interesting scenarios.\n",
      "\n",
      "The AI is a very powerful\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dragons vs AI\n",
      "\n",
      "The AI is a very powerful tool that can be used to create a very complex game. It can be used to create a very complex game. It can be used to create a very complex game. It can be used to create a very complex game. It can be used to create a very complex game. It can be used to create a very complex game. It can be used to create a very complex game. It can be used to create a very complex game\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dragons vs AI\n",
      "\n",
      "If you have any questions about the AI, please email me at [email protected]\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dragons vs AI\n",
      "\n",
      "I am not going to go into the AI aspect of this game and just talk about it. I am going to focus on the AI aspect, which is how you interact with the player.\n",
      "\n",
      "First, let me take a moment to clarify what is going on in the game. We are talking about the AI. We are talking about how you interact with the player. We are talking about how you interact with the AI.\n",
      "\n",
      "Let me start with the AI\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dragons vs AI\n",
      "\n",
      "I can't think of a better way to describe the AI game of \"AI vs. humans\". The AI is the human-controlled machine, and then the human-controlled machine is the AI. The AI is the human-controlled machine, and then the AI is the AI.\n",
      "\n",
      "The AI is the human-controlled machine, and then the human-controlled machine is the AI. The AI is the human-controlled machine, and then the AI is the\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dragons vs AIBs, and their respective battles have been in the spotlight for quite some time. Both players have been accused of overthinking the issue, and that has led to a lot of drama as all AIBs have come into it and have tried to pull the spotlight on each other. And because of that, it's not hard to find some really great AIBs who have been in these very battles.\n",
      "\n",
      "Some know the exact tactics that I used during the time I was in the\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dragons vs AI\n",
      "\n",
      "Trying to understand this question\n",
      "\n",
      "What is the difference between AI and human?\n",
      "\n",
      "I found a way to solve the question. I added an example of trying to determine what is and is not the same as if it were a human.\n",
      "\n",
      "For example, I use a computer to perform a task. The computer performs a series of tasks and the computer calculates the number of words or numbers that it generates per minute in response to these tasks. The computer\n",
      "----------------------------------\n",
      "Dragons vs AI: We Are A Game That Needs That\n",
      "\n",
      "We already saw the first big reveal of the final chapter of the epic game, The Witcher 3: Wild Hunt, and we've been working tirelessly on a whole slew of new things to make it even better.\n",
      "\n",
      "The Witcher 3: Wild Hunt is a full game in which the player takes to the battlefield to deal with dangerous creatures such as wolves, dragons, and other ferocious beasts. The Witcher 3 has been making a big\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_return_sequences):\n",
    "    print(\"----------------------------------\")\n",
    "    prompt = 'Dragons vs AI'\n",
    "    result = generator(prompt, max_length=100, temperature=0.1)\n",
    "    print(result[0]['generated_text'])\n",
    "    \n",
    "for i in range(num_return_sequences):\n",
    "    print(\"----------------------------------\")\n",
    "    prompt = 'Dragons vs AI'\n",
    "    result = generator(prompt, max_length=100, temperature=0.5)\n",
    "    print(result[0]['generated_text'])\n",
    "    \n",
    "for i in range(num_return_sequences):\n",
    "    print(\"----------------------------------\")\n",
    "    prompt = 'Dragons vs AI'\n",
    "    result = generator(prompt, max_length=100, temperature=0.9)\n",
    "    print(result[0]['generated_text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
