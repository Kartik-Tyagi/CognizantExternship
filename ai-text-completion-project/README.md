This program allows you to query a Google-trained LLM model called Gemma. (The size being used is 2b so large RAM is not required)

Before tunning the program, install ollama and add it to your PATH.
Installation can be done through: https://ollama.com/download

Once installed, run the following command in terminal to be able to query the Gemma model:
ollama pull gemma:2b

You are all set, just run the script and follow the instructions